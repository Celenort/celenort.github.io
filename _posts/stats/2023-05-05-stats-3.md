---
title: '통계학 3장 - 확률과 확률분포'
layout: single
categories:
  - study
  - stats
tags: []
mathjax: true
---

### 확률

- 사건 (event) : 발생가능한 결과들의 집합
- 단순사건 혹은 근원사건 : 오직 한 개의 원소로 이루어진 사건
- 표본공간(sample space) : 일어날 수 있는 모든 가능한 단순사건을 모아 집합으로 표현한 것, S로 표시.
    - 모든 원소를 포함(exhaustive)
    - 상호배반 (mutually exclusive)
    - (ex) 주사위에서 S = {1, 2, 3, 7보다 작은 짝수} -> "5" 미포함 (모든원소포함 X), "2" 중복(상호배반적 X), "7보다 작은 짝수" 단순사건 X
- 확률의 고전적 정의 : N개로 구성된 표본공간 S에서 각각의 근원사건 일어날 가능성 같은 경우 m개의 원소로 구성된 사건 A의 확률
    >$$P(A) = \frac m n$$
    - 유한개의 원소일때만 적용, 각 결과마다의 가능성이 같지 않으면 적용안됨
- 확률의 공리적 정의 : $P(A)$의 값 0~1 사이, 표본공간의 확률은 1, 배반이면 $P(A\cup B) = P(A)+P(B)$ 이면 $P(A)$를 A의 확률이라 함
- 조건부 확률(conditional probability) : 한 사건이 일어났다는 조건하에 다른 사건이 일어날 확률
    >$$P(B\vert A) = \frac {P(A \cap B)} {P(A)} \\ (P(A)>0)$$
    - 사건 A를 표본공간으로 간주
- 전확률공식 : 직접 계산하기 힘든 확률 B, S를 A1~An으로 분할하면, 
    >$$P(B) = P(A_1 \cap B) + \cdots P(A_n \cap B) = P(B\vert A_1)P(A_1) + ... + P(B\vert A_n)P(A_n)$$
- 베이즈 정리 : 조건 확률 구할 때 조건 상황이 역으로 되어있는 확률 구하기
    >$$P(A_i\vert B) = \frac {P(A_i\cap B)} {P(B)} = \frac {P(A_i)P(B\vert A_i)} {P(A_1)P(B\vert A_1) + \cdots + P(A_n)P(B\vert A_n)}$$
- 독립사건 : 사건 A가 일어날 확률이 사건 B가 일어날 확률에 아무런 영향을 미치지 않음
    >$$P(A \cap B) = P(A)P(B) \\ P(A\vert B) = P(A) \\ P(B\vert A) = P(B)$$
    성립
    - 독립이 아니면 상호종속
    - 상호배반이면 독립? (그렇지 않다.) $unless$  $P(A)$  or $ P(B)=0$ , 공집합은 모든 사건과 독립
- 확률변수 : 표본 공간에서 정의된 실수값 함수
    - 확률변수 (random variable) : X, Y 등 대문자로 표현
    - 확률변수가 취하는 값 -> x, y 등 소문자로 표현 
        >$$P(X=x)$$
    - 확률분포(probability distribution) : 확률변수 X의 값에 따라 확률이 흩어져 있는지를 합이 1인 양수로 나타낸 것
- 이산확률변수 : 확률변수가 취할 수 있는 값이 셀 수 있는(countable) 값인 확률변수
    - $p(x) = P(X=x_i)$ when $x=x_i(i=1, 2,\cdots)$  when $x\neq x_i$ $p(x)$를 확률질량함수(probability mass function)
    - $0\leq p(x)\leq1$, 모든 x에 대해서 p(x) 값 적분하면 1
- 연속확률변수 : 확률변수 취하는 값이 셀수 없는 경우 (어떤 구간내의 모든값 취할 수 있는 경우) 의 확률변수
    - $p(x)\geq0$, $-\infty \sim \infty$ 적분하면 1, $P(a\leq X\leq b) = \int_a^b p(x) dx$
    - 임의의 c에 대해서 P(X=c) = 0, a, b같은 경계값의 포함여부는 확률변수의 값에 상관이 없음

### 확률분포의 대표값

- 확률변수 X의 평균(mean) 또는 기대값(expected value) 
    >$$E(X) = \Sigma xp(x)$$
    or
    >$$E(X) = \displaystyle\int_{-\infty}^{\infty} xp(x)dx$$
- 확률변수의 분산(variance)와 표준편차(standard deviation)
    - 산포를 나타내는 대표값, X의 평균이 $\mu$, 확률질량/밀도함수가 $p(x)$,
        >$$Var(X) = E[(X-\mu)^2] = \Sigma (x-\mu)^2 p(x)$$

        or

        >$$Var(X) = \displaystyle\int_{-\infty}^{\infty} (x-\mu)^2 p(x)dx$$
    > $$sd(X) = \sqrt{Var(X)}=\sigma \\ Var (X) = E(X^2)-\mu^2$$
    - 분산과 표준편차의 성질
        >$$Var(aX+b) = a^2Var(X)$$

### 확률변수의 표준화
- 표준화 : 확률변수 X에 대해서 평균 $\mu$를 뺀 다음 표준편차로 나누는 것
    > $$Z = X-\frac {E(X)} {sd(X)} $$
    - Z의 평균은 0, 분산은 1
    
### 결합확률분포

- 결합확률분포(두 개 이상의 확률변수를 동시에 고려할 때 이들 사이의 확률적 관계 나타내는 방법) : X, Y에 대해 순서짝에 확률 흩어진 것을 합이 1인 양수로 나타낸 것
    - 결합확률질량함수 : 이산확률변수 $X, Y$가 각각 $x1, x2, \cdots , y1, y2, \cdots$ 의 값을 취할 때 (X,Y)가 (x,y)일 확률이 $p(x,y) = P(X=x_i, Y=y_j)$
    - 결합확률질량함수 성질 : 0과 1사이, x, y에 대해서 이중시그마 하면 1
    - 주변확률질량함수 : X, Y의 분포 결정해줌
        >$$p_1(x) = \displaystyle\Sigma^x p(x,y) \\ p_2(y) = \displaystyle\Sigma^y p(x,y)$$
    - 두 확률변수의 함수도 자신의 확률분포 가지는 확률변수.
    - g, g1, g2를 X와 Y의 함수라고 한다면,
        >$$E(g(X,Y)) = \displaystyle\Sigma^x \displaystyle\Sigma^y g(x,y)p(x,y)$$
    - 상수 빼서 따로 쓸수도있음.
- 두 확률변수의 독립성 : X와 Y의 결합확률변수 p(x,y), X의 주변확률함수 p1(x), Y의 주변확률함수 p2(y)에 대해 $p(x,y)=p_1(x)p_2(y)$이면 독립
- 공분산(covariance) : 
    >$$Cov(X,Y) = E[(X-\mu_1)(Y-\mu_2)] = E(XY) -E(X)E(Y)$$
- 상관계수(correlation coefficient) : 확률변수 X, Y 표준화한 것의 곱의 기댓값
    >$$Corr(X,Y) = \frac {Cov(X,Y)} { sd(X) sd(Y)}$$

    >$$-1\leq Corr(X,Y)\leq 1$$
- 공분산과 상관계수 성질
    >$$Cov(aX+b, cY+d) = ac Cov(X,Y) \\ Corr(aX+b, cY+d) = \pm Corr(X,Y)$$
    (ac의 부호에 따라)
    >$$Var(X\pm Y) = Var(X)+Var(Y) \pm 2Cov(X,Y)$$
- 두 변수가 서로 독립이면
    >$$E(XY) = E(X)E(Y)$$ 
    왜냐면 
    >$$p(x_i, y_j) = p_1(x_i)p_2(y_j) \\ Cov(X,Y)=0, Corr(X,Y) = 0 \\ Var(X\pm Y) = Var(X)+Var(Y)$$
