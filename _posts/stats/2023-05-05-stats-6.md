---
title: '통계학 6장 - 분포에 관한 추론'
layout: single
categories:
  - study
  - stats
tags: []
mathjax: true
sidebar:
  nav: "study"
auther_profile: false
---

### 표본분산의 분포

- 변동성이 크면 평균적으로는 맞아도 안맞는 불량이 많을수 있으므로, 표본문산이라는 통계량을 통해 모분산에 대한 추론 할 수 있음.
- E(s^2)= sigmma^2
- 모집단이 정규분포를 따르고, 단순임의추출을 한 n개의 랜덤표본의 표본분산 s^2에 대하여, (n-1)s^2 / sigma^2 ~ kai^2(n-1) 성립.

### 카이제곱 분포

- 확률변수 Z_1 ~ Z_n 이 N(0,1)의 랜덤표본, Z_1^2+... + Z_k^2 ~ kai^2 (k)
- 카이제곱 분포의 분위수 (1-alpha) 분위수 : 오른쪽 꼬리의 넓이가 alpha 가 되는 값이 kai^2_alpha(k) 임. P{V>=kai^2 alpha(k)} = alpha
- 왼쪽 넓이 alpha : kai^2_1-alpha (k) 

### 카이제곱 분포의 가법성

- V1 ~ kai^2 k1, V2 ~ kai^2 k2 고 V1, V2가 독립이면 V1+V2 ~ kai^2 (k1+k2)
- X1~ Xn 이 정규분포 N(mu, sigma^2)의 랜덤표본이면, 이를 정규화 한 것의 제곱의 합이 카이제곱분포의 정의에의해 kai^2(n)이 됨. 이 식에 분자에 xbar를 더하고 빼서 정리, sigma(xi-xbar/sigma)^2  + n(xbar-mu/sigma)^2이 되므로, s^2의 정의에 의해서  kai^2(n) = (n-1)s^2/sigma^2 + kai^2(1)이니까 가법성에 의해 (n-1)s^2/sigma^2 ~ kai^2(n-1)

### 모분산의 신뢰구간

- 1-alpha = P(kai^2_(1-alpha/2) (n-1) <= (n-1) s^2 / sigma^2 <= kai^2_(alpha/2) (n-1))  이걸 sigma^2에 대해서 정리하면, 유의수준 alpha에 대한 모분산의 신뢰구간.
- sigma^2으로 정리하면, {(n-1)s^2/kai^2_alpha/2 (n-1), (n-1)s^2/kai^2_(1-alpha/2) (n-1)

### 모분산의 가설검정

- 검정통계량은 kai^2 = (n-1) s^2 / simga_0^2 ~kai^2(n-1) 
- 단측검정 : H1 : sigma^2>sigma_0^2 -> 유의확률 P = P(kai^2 >=kai_0^2), 유의확률 alpha의 기각역 : kai_0^2 >= kai_alpha^2(n-1) 
- 단측검정 : H1 : sigma^2<sigma_0^2 -> 유의확률 P = P(kai^2<=kai_0^2), 유의확률 alpha의 기각역 : kai_0^2<=kai_alpha^2(n-1) 
- 양측검정 : 어느쪽에 떨어졌는지에 따라, 오른쪽에 떨어졌다면 유의 확률 : P = 2P(kai^2 >=kai_0^2) 왼쪽에 떨어졌다면 P = 2P(kai^2<=kai_0^2) (Rough하게) 기각역은 kai_0^2 >=kai_alpha/2^2 (n-1) or kai_0^2<=kai_(1-alpha/2) ^2 (n-1)이다.

### 두 모집단의 모평균의 비교

- 두 모집단의 모평균에 차이가 있는지를 알아보기 위해, H_0 : mu_1 - mu_2 = 0 H_1 : mu_1 - mu_2 =/= 0

- 두 모평균 차의 추정치 = hat(mu_1 - mu_2) = bar(x_1) - bar(x_2)
- 두 모집단의 평균 비교에 필요한 가정
    1. 각 그룹에서 관측값들은 각 모집단에서의 랜덤표본임.
    2. 서로 다른 그룹에서의 관측값들은 독립적으로 관측됨
    3. 두 모집단은 각각 정규분포를 따름 (CLT에 의해 표본이 크면 무시될수 있음)
- 랜덤화(randomization) : 각 처리를 적용할 실험단위를 랜덤하게 정하는 과정, 두가지의 처리를 적용하여 비교하는 경우 전체 실험단위를 랜덤하게 두 그룹으로 나누어 별도의 처리 적용해야 위 가정사항 만족.

### xbar1-xbar2(표본평균의 차)의 표본분포

- 점추정 (hat(mu1-mu2) = xbar1-xbar2 )
- Xbar1 - Xbar2 의 기댓값은 mu1-mu2  즉 비편향 추정량 (비편향추정량)
- Var(xbar1-xbar2) = Var(xbar1)+Var(xbar2) -2Cov(Xbar1, Xbar2) = sigma1^2/n1 + sigma2^2/n2 (둘이 독립이므로 공분산 term 사라짐)
- 모분산을 아는 경우
    1. 두 모집단이 정규분포 따르면 Xbar1-Xbar2를 표준화시킨 Z ~ N . 
    2. 정규분포 따르지 않아도 표본수 증가하면 CLT에 따라 표준정규분포에 가까워짐.
- 검정통계량 Z = (xbar1_xbar2 -(mu1-mu2))  / sqrt(sigma1^2/n1 + sigma2^2/n2) ~N(0,1)
- 100(1-alpha) % 신뢰구간 : (xbar1-xbar2) +- z_alpha/2 sqrt(sigma1^2/n1 + sigma2^2/n2) - 모평균의 추정과 동일한 방법으로 신뢰구간 구하면 됨.
- 양측검정 : (-inf, -z_alpha/2), (z_alpha/2, inf) 가 기각역, 기각역의 넓이의 합이 alpha
- 단측검정 : z<-z_alpha or z>z_alpha 

### 두 모평균의 차이에 대한 추론(등분산, 정규모집단의 경우)

- sigma 1, sigma 2를 모르는 경우이지만, sigma1^2 = sigma2^2 = sigma^2라는 등분산으로 가정.
- 합동모분산(pooled sample variance) : S_p^2
- sigma^2의 추정량으로, S1^2, S2^2의 자유도의 가중평균의 형태로 정의됨.
- (n1-1)s1^2 + (n2-1)s2^2 / n1+n2-2
- hat(Var(xbar1-xbar2) ) = sp^2(1/n1 + 1/n2) 
- xbar1-xbar2를 추정된 분산으로 표준화한 통계량은 자유도가 n1+n2-2인 t분포를 따르게 됨.
- (xbar1-xbar2) - (mu1-mu2) / sp sqrt(1/n1 + 1/n2) ~ t(n1+n2-2)
- pf) 위에서 t분포 증명과 동일한 방식
- 100(1-alpha) % 신뢰구간 : xbar1-xbar2 +-t_alpha/2 (n1+n2-2) s_p sqrt(1/n1+ 1/n2)

### 자유도 개념

- x1, x2, ... xn 에서 xbar를 알고 있음. 즉 x_k 중 하나를 몰라도 xbar를 알면 x_k를 구할 수 있음. 
- 자유도 : 자유롭게 관찰될 수 있는 것의 갯수. n-1개는 마음대로 작성할 수 있지만, 마지막 1개는 평균값에 맞춰야 하기 때문에...  자유도는 n-1

### 두 모평균의 차이에 대한 추론 (등분산, 대표본의 경우, 정규분포 X)

- Z = (xbar1-xbar2) - (mu1-mu2) / sp sqrt(1/n1 + 1/n2) .~ N(0,1)
- n1, n2>=30 이면 정규분포 가정 가능 (CLT에 의해)

### 두 모평균의 차이에 의한 추론 (이분산 가정, 정규분포 모집단 가정)

- xbar1 - xbar2 의 분산  : 이분산의 경우 표본평균간의 독립성에 의해
- hat(Var(xbar1-xbar2)) = s1^2/n1 + s2^2/n2 
- T = (xbar1-xbar2) - (mu1-mu2) / sqrt(s1^2/n1 + s2^2/n2) ~ t(df)


### 두 모평균의 차이에 의한 추론 (이분산 가정, 대표본의 경우)

- (xbar1-xbar2) - (mu1-mu2) / sqrt(s1^2/n1 + s2^2/n2) .~ N(0,1)
- n1, n2>=30

### 대응비교에 의한 모평균의 비교

- 동일한 개체에 대해 실험 전과 실험 후의 측정값의 차이를 비교하는 경우에 사용.
- 대응비교 : 두 모집단의 평균을 비교할 때 동질적 비교대상들로 쌍을 이루어 각 쌍 내에서의 차를 이용하여 비교하는 방법
- 각 실험에 참여하기로 개체 자체의 특성이 있기 때문에 두 모집단으로 나누어 비교하는 것이 아닌 대응비교하는 것이 더 나음.
- 실험 단위(experimental unit) : 가축과 같이 비교의 목적을 위해 그 매개체로 사용되는 대상
- 처리(treatment) : 공장이 있는 환경과 같이 실험단위에 적용되어 특성치를 결정지어 주는 것.
- 처리 효과 (treatment effect) : 비교대상인 특성치
- 이 때는 두 집단이 독립이라는 가정을 만족 못함 ( 대응되는 것이 같은 개체이기 때문) -> 두 집단의 측정값의 차이를 이용하여 추론한다. 

- 주어진 자료 : (X1,Y1), ... , (Xn, Yn) 
- mu1 = E(xi), mu2 = E(yi) 의 차이를 비교하기 위해 자료에서 얻은 측정값의 차인 Di를 구하여 그 차이가 0인가 에 대한 문제로 바꾸어 추론.
- Di = Xi-Yi, 이 것이 정규분포로부터의 랜덤표본이라 가정, 표본크기가 클 때는 근사적으로 성립, -> 실험단위를 랜덤 추출, 처리의 적용순서도 랜덤하게 정해야 함.
- Di의 기댓값 E(Di) = mu1 - mu2 = muD
- 모평균 muD의 추정량 : 표본평균 Dbar = 1/n sigma di
- 모분산의 추정량 : 표본분산 sD^2 = 1/n-1 sigma(di-dbar)^2
- Dbar 의 기댓값 : muD, Dbar의 분산 = sD^2/n
- H_0 : mu1-mu2 = muD  = 0
- T = Dbar-muD / sqrt(sD^2/n) ~ t_n-1 (모분산을 몰라서 추정했으므로, t분포)

### 등분산 이표본 비교 vs 대응비교

- H_0 : mu_x = mu_y (or muD = 0)
- 등분산 이표본에서의 검증통계량 T = (xbar - ybar) / sp sqrt(1/n + 1/n) ~ t(2n-2), 
- 대응비교에서의 검증통계량 T = Dbar / sqrt(sp^2/n) ~ t(n-1)
- 분자는 동일하나, xbar - ybar의 분산에서 두 추정량이 독립이 아니라면, (두 변수가 양의 상관관계를 보이면) -> 분모가 더 작아짐 -> 대응비교의 검정통계량 값이 커져서 H_0 기각하기 쉬워짐. -> 대응비교의 장점.
- t분포의 자유도 (등분산 이표본 비교에서는 자유도가 2n-2, 대응비교는 n-1) 이므로, 같은 조건일 때 대응비교의 귀무가설의 기각이 더 힘들어짐. (자유도 작아지면, alpha를 만족하는 분위수 값이 커지게 됨. 즉 기각이 어려워짐)
- 즉 실험단위들이 이질적, 양의 상관관계 보이면 대응비교가 맞고, 그렇지 않으면 대응비교의 penalty(자유도 작음) 떄문에 장점 사라짐.

### 두 모비율의 차이에 의한 추론

- 두 모집단에서 각각 n1, n2개의 랜덤표본을 독립추출, 관심대상인 속성이 두 표본에서 나타나는 도수를 각각 X1, X2개라고 하면, 표본비율은 p1hat = X1/n1, p2hat = X2/n2 
- X1, X2는 각각 B(n1, p1), B(n2, p2)를 따르고, 두 모비율의 차의 추정량 hat(p1-p2) = X1/n1-X2/n2 가 됨. 
- Var(hat(p1-p2)) = p1(1-p1)/n1 + p2(1-p2)/n2 이므로 표준오차는 sqrt(Var(hat(p1-p2)))
- 표본크기 n1, n2가 큰 경우 표본비율들이 정규분포 따름, 둘이 독립이니까 두 비율의 차 p1hat-p2hat .~ N(p1-p2, p1(1-p1)/n1+p2(1-p2)/n2)
- 비율에서 n이 크다 -> np1hat, n(1-p1hat) np2hat, n(1-p2hat) >=5
- p1-p2(모수)에 대한 100(1-alpha) % 신뢰구간 : hat(사용)

### 두 모비율의 비교를 위한 검정

- H_0 : p1 = p2 라고 검정해야하므로, p1=p2=p라고 생각하자.
- p의 추정량 phat (합동표본비율, pooled sample proportion) = X1+x2 / n1+n2
- Var(p1hat - p2hat ) = p(1-p) (1/n1+1/n2)
- hat(Var(p1hat-p2hat)) = phat(1-phat) (1/n1+1/n2)